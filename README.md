# BigLittleDecoder
Big Little Decoder 是一个简单的框架，可以实现更快的生成推理。它可以将文本生成速度大幅加快约 2 倍，而不会影响各种文本生成场景的性能。此外，它是一个简单的即插即用解决方案，无需培训或架构重新设计。
关键思想如下：
1.BiLD 将大部分简单的单词决策转移到较小的模型，并且仅在需要时将控制切换回较大的模型。
2.当小模型遇到难以预测的单词时，它会“回退”到大模型。
3.如果小模型犯了错误，大模型可以“回滚”预测来纠正错误。
4.这种协作文本生成将小模型的快速自回归执行与大模型的准确高效的非自回归执行相结合。
